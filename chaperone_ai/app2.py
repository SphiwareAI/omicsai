from flask import Flask, render_template, request, redirect, url_for, send_from_directory, flash
from werkzeug.utils import secure_filename
import os
import subprocess
import pandas as pd
import joblib
from keras.models import load_model
import numpy as np
from sklearn.preprocessing import MinMaxScaler

app = Flask(__name__)

# Configuration
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['OUTPUT_FASTQC'] = 'outputs/output_fastqc'
app.config['OUTPUT_VELVET'] = 'outputs/output_velvet'
app.config['ALLOWED_EXTENSIONS'] = {'fastq', 'gz'}

# Ensure the upload and output directories exist
for key in app.config:
    if key.startswith('OUTPUT_') and not os.path.exists(app.config[key]):
        os.makedirs(app.config[key])

# Function to check if a file has an allowed extension
def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/check_quality', methods=['GET', 'POST'])
def check_quality():
    if request.method == 'POST':
        file = request.files['file']
        if file.filename == '':
            return redirect(request.url)

        filename = os.path.join(app.config['UPLOAD_FOLDER'], secure_filename(file.filename))
        file.save(filename)

        cmd = ['./FastQC/fastqc', filename, '-o', 'outputs/output_fastqc']
        subprocess.run(cmd)

        # Extract the name of the HTML report generated by FastQC
        html_report = secure_filename(file.filename.replace('.fastq.gz', '_fastqc.html'))
        zip_report = secure_filename(file.filename.replace('.fastq.gz', '_fastqc.zip'))

        return render_template('quality_check.html', uploaded=True, html_report=html_report, zip_report=zip_report)

    return render_template('quality_check.html', uploaded=False)

@app.route('/genome_assembly', methods=['GET', 'POST'])
def genome_assembly():
    feedback = None
    contigs = None
    stats = None
    OUTPUT_VELVET = 'outputs/output_velvet'

    if request.method == 'POST':
        files = request.files.getlist('file')

        if len(files) != 2:
            feedback = "Please upload exactly two files for paired-end reads."
            return render_template('genome_assembly.html', feedback=feedback)

        file_paths = []
        for file in files:
            if file and allowed_file(file.filename):
                filename = secure_filename(file.filename)
                filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
                file.save(filepath)
                file_paths.append(filepath)

        hash_length = 31
        cmd_velveth = f"velveth {OUTPUT_VELVET} {hash_length} -shortPaired -separate -fastq {' '.join(file_paths)}"
        cmd_velvetg = f"velvetg {OUTPUT_VELVET}"
        
        #cmd_velveth = f"./velvet_1.2.10/velveth {OUTPUT_VELVET} {hash_length} -shortPaired -separate -fastq {' '.join(file_paths)}"
#cmd_velvetg = f"./velvet_1.2.10/velvetg {OUTPUT_VELVET}"


        os.system(cmd_velveth)
        os.system(cmd_velvetg)

        # Check if contigs.fa and stats.txt exist
        if os.path.exists(os.path.join(OUTPUT_VELVET, 'contigs.fa')):
            contigs = 'contigs.fa'
        if os.path.exists(os.path.join(OUTPUT_VELVET, 'stats.txt')):
            stats = 'stats.txt'

        feedback = "Upload and assembly successful!"

    return render_template('genome_assembly.html', feedback=feedback, contigs=contigs, stats=stats)

@app.route('/outputs/<path:subdir>/<filename>')
def output_files(subdir, filename):
    return send_from_directory(os.path.join('outputs', subdir), filename, as_attachment=False)

@app.route('/gene_prediction', methods=['POST', 'GET'])
def gene_prediction():
    feedback = None
    protein_file = None

    if request.args.get('from_assembly') == 'true':
        contigs_path = os.path.join(OUTPUT_VELVET, 'contigs.fa')
        if os.path.exists(contigs_path):
            output_path = os.path.join(OUTPUT_PRODIGAL, 'out.faa')
            cmd = ['prodigal', '-i', contigs_path, '-p', 'normal', '-q', '-a', output_path]
            subprocess.run(cmd)
            feedback = "Gene prediction was successful!"
            protein_file = 'out.faa'
        else:
            feedback = "contigs.fa file not found. Please run the genomic assembly first."

    elif 'file' in request.files:
        uploaded_file = request.files['file']
        
        if uploaded_file.filename == '':
            feedback = "No file selected."
        elif uploaded_file and allowed_file(uploaded_file.filename):
            filename = secure_filename(uploaded_file.filename)
            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            uploaded_file.save(filepath)
            output_path = os.path.join(OUTPUT_PRODIGAL, 'out.faa')
            cmd = ['prodigal', '-i', filepath, '-p', 'normal', '-q', '-a', output_path]
            subprocess.run(cmd)
            feedback = "Gene prediction was successful!"
            protein_file = 'out.faa'
        else:
            feedback = "Invalid file type. Please upload a .fa file."

    return render_template('gene_prediction.html', feedback=feedback, protein_file=protein_file)

#@app.route('/index', methods=['POST', 'GET'])
#def display_index():
#    user_id = request.cookies
#    session_id = request.cookies['session']
#    files = os.listdir(os.path.join(app.config['UPLOAD_FOLDER'], session_id))
#    print('user:', user_id)
#    return render_template('index.html', files=files, classifiers=ast.literal_eval(config['classifiers']))

def preprocess_sequences(sequences):
    # Preprocess the sequences if needed
    # For enzyme sequences, you can apply any specific preprocessing steps here.
    return sequences

def load_trained_model_and_vectorizer():
    # Load the already trained model
    model_path = 'lr_tf_idf_multiclass_SMOTE.sav'
    model = joblib.load(model_path)

    # Load the vectorizer used during training
    vectorizer_path = 'vectorizer_bio.pkl'
    vectorizer = joblib.load(vectorizer_path)

    return model, vectorizer

# Flask routes

@app.route('/ml_preprocessing', methods=['POST', 'GET'])
def ml_preprocessing():
    if request.method == 'POST':
        # Check if the post request has the file part
        if 'file' not in request.files:
            flash('No file part', 'error')
            return redirect(request.url)

        file = request.files['file']

        if file.filename == '':
            flash('No selected file', 'error')
            return redirect(request.url)

        if file and allowed_file(file.filename):
            # Save the uploaded file to the UPLOAD_FOLDER
            if not os.path.exists(app.config['UPLOAD_FOLDER']):
                os.makedirs(app.config['UPLOAD_FOLDER'])
            file_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
            file.save(file_path)

            # Get the selected prediction type
            prediction_type = request.form.get('prediction_type')

            # Redirect to the specific prediction page based on the selected type
            if prediction_type == 'protein':
                prediction_results = protein_prediction(file_path)
                return redirect(url_for('protein_prediction', file_path=file_path))
            elif prediction_type == 'enzyme':
                prediction_results = enzyme_prediction(file_path)
                return redirect(url_for('enzyme_prediction', file_path=file_path))
            elif prediction_type == 'peptide':
                prediction_results = peptide_prediction(file_path)
                return redirect(url_for('peptide_prediction', file_path=file_path))

    return render_template('ml_processing.html')


# Flask routes
model = load_model('DPPIV_tensorflow_model')
# embeddings function
def esm_embeddings(peptide_sequence_list: list):
    # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long,
    #         or you have too many sequences for transformation in a single converting,
    #         you conputer might automatically kill the job.
    # return a panda.dataframe
    import torch
    import pandas as pd
    import esm
    import collections
    # load the model
    # NOTICE: if the model was not downloaded in your local environment, it will automatically download it.
    model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()
    batch_converter = alphabet.get_batch_converter()
    model.eval()  # disables dropout for deterministic results

    # load the peptide sequence list into the bach_converter
    batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)
    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)
    ## batch tokens are the embedding results of the whole data set

    # Extract per-residue representations (on CPU)
    with torch.no_grad():
        # Here we export the last layer of the EMS model output as the representation of the peptides
       # model'esm2_t6_8M_UR50D' only has 6 layers, and therefore repr_layers parameters is equal to 6
        results = model(batch_tokens, repr_layers=[6], return_contacts=True)
    token_representations = results["representations"][6]

    # Generate per-sequence representations via averaging
    # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.
    sequence_representations = []
    for i, tokens_len in enumerate(batch_lens):
        sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))
    # save dataset
    # sequence_representations is a list and each element is a tensor
    embeddings_results = collections.defaultdict(list)
    for i in range(len(sequence_representations)):
        # tensor can be transformed as numpy sequence_representations[0].numpy() or  sequence_representations[0].to_list
        each_seq_rep = sequence_representations[i].tolist()
        for each_element in each_seq_rep:
            embeddings_results[i].append(each_element)
    embeddings_results = pd.DataFrame(embeddings_results).T
    return embeddings_results

# normalized the embeddings
X_train_data_name = 'DPPIV_train_esm2_t6_8M_UR50D_unified_320_dimension.csv'
X_train_data = pd.read_csv(X_train_data_name, header=0, index_col=0, delimiter=',')
X_train = np.array(X_train_data)
# normalize the X data range
scaler = MinMaxScaler()
scaler.fit(X_train)
# scaler.transform will automatically transform the pd.dataframe into a np.array data format

# collect the output
def assign_activity(predicted_class):
    import collections
    out_put = []
    for i in range(len(predicted_class)):
        if predicted_class[i] == 0:
            #out_put[int_features[i]].append(1)
            out_put.append('active')
        else:
            #out_put[int_features[i]].append(2)
            out_put.append('non-active')
    return out_put


@app.route('/protein_prediction', methods=['GET', 'POST'])
def protein_prediction():
    # Add your protein prediction logic here
    return render_template('protein_prediction.html', file_path=file_path, prediction_results=prediction_results)

@app.route('/enzyme_prediction', methods=['GET', 'POST'])
def enzyme_prediction():
    # Add your enzyme prediction logic here
    # Get the file_path from the form data
    file_path = request.form.get('file_path')

    # Load the already trained model and vectorizer
    model_path = 'lr_tf_idf_multiclass_SMOTE.sav'
    vectorizer_path = 'vectorizer_bio.pkl'
    
    # Read and preprocess the sequences
    data = pd.read_csv(file_path)
    sequences = data['Protein Sequence'].tolist()
    preprocessed_sequences = preprocess_sequences(sequences)

    # Transform the sequences using the vectorizer
    X_test = vectorizer.transform(preprocessed_sequences)

    # Get the predictions
    predictions = model.predict(X_test)

    # Map class labels to their respective names (if needed)
    class_mapping = {
        0: 'ligases',
        1: 'lyases',
        2: 'hydrolases',
        3: 'isomerase',
        4: 'translocase',
        5: 'transferases',
        6: 'non enzyme',
        7: 'oxidoreductase'
    }

    predicted_labels = [class_mapping[label] for label in predictions]
    

    # Combine the sequences with the predictions
    data['Predicted Label'] = predicted_labels
    return render_template('enzyme_prediction.html', data=data.to_html(index=False))

@app.route('/peptide_prediction', methods=['GET', 'POST'])
def peptide_prediction():
    # Add your peptide prediction logic here
    int_features  = [str(x) for x in request.form.values()]
    sequence_list=int_features[0].split(',') 
    peptide_sequence_list = []
    for seq in sequence_list:
        format_seq = [seq, seq]  # the setting is just following the input format setting in ESM model, [name,sequence]
        tuple_sequence = tuple(format_seq)
        peptide_sequence_list.append(tuple_sequence)  # build a summarize list variable including all the sequence information

    embeddings_results = esm_embeddings(peptide_sequence_list) #conduct the embedding
    normalized_embeddings_results = scaler.transform(embeddings_results) # normalized the embeddings

    # prediction
    predicted_protability = model.predict(normalized_embeddings_results, batch_size=1)
    predicted_class = []
    for i in range(predicted_protability.shape[0]):
        index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]
        predicted_class.append(index) # get the class of the results
    predicted_class = assign_activity(predicted_class) # transform results (0 and 1) into 'active' and 'non-active'

    return render_template('peptide_prediction.html',prediction_text="Peptide sequence is predicted to be {}".format(predicted_class))

    #return render_template('peptide_prediction.html', file_path=file_path, prediction_results=prediction_results)


if __name__ == "__main__":
    app.run(debug=True)
