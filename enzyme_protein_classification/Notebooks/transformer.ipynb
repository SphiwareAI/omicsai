{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from preprocess import PreProcess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import re\n",
    "import html\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bbc_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"Pernod takeover talk lifts Domecq\\n\\nShares ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'Qwest may spark MCI bidding war\\n\\nUS phone ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'Dogged Federer claims Dubai crown\\n\\nWorld n...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'Oscars race enters final furlong\\n\\nThe race...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b\"Hearts of Oak 3-2 Cotonsport\\n\\nHearts of Oa...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document       Category\n",
       "0  b\"Pernod takeover talk lifts Domecq\\n\\nShares ...       business\n",
       "1  b'Qwest may spark MCI bidding war\\n\\nUS phone ...       business\n",
       "2  b'Dogged Federer claims Dubai crown\\n\\nWorld n...          sport\n",
       "3  b'Oscars race enters final furlong\\n\\nThe race...  entertainment\n",
       "4  b\"Hearts of Oak 3-2 Cotonsport\\n\\nHearts of Oa...          sport"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_process_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    column_name = data.columns[0]\n",
    "    # print(column_name)\n",
    "    pre_processor = PreProcess(data, column_name)\n",
    "    # todo: change code to provide all functions in class definition.\n",
    "    data = pre_processor.clean_html()\n",
    "    data = pre_processor.remove_non_ascii()\n",
    "    data = pre_processor.remove_spaces()\n",
    "    data = pre_processor.remove_punctuation()\n",
    "    data = pre_processor.stemming()\n",
    "    data = pre_processor.lemmatization()\n",
    "    data = pre_processor.stop_words()\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data.Document, data.Category, test_size=0.20)\n",
    "    tfidf_transformer = TfidfVectorizer(min_df=1)\n",
    "    train_vectors = tfidf_transformer.fit_transform(train_x)\n",
    "    return train_vectors, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = read_process_data('bbc_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.todense(),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(df):\n",
    "    df = df.apply(lambda x: \"\".join(i for i in x if ord(i) < 128))\n",
    "    return df\n",
    "class PreProcess(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This class contains all text pre-processing function\n",
    "    # Input parameters: Dataframe, Column_name on which function needs to be applied\n",
    "    # Output parameters: Return dataframe after applying operations\n",
    "    \"\"\"\n",
    "    # todo: Pass functions as a list of arguments to apply in the class\n",
    "    # todo: make set of words before applying all operations to reduce processing time.\n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.lemmatiser = WordNetLemmatizer()\n",
    "        # pass\n",
    "\n",
    "    def clean_html(df):\n",
    "        \"\"\"remove html entities\"\"\"\n",
    "        df = df.apply(html.unescape)\n",
    "        return df\n",
    "\n",
    "    def remove_spaces(df):\n",
    "        df = df.apply(lambda x: x.replace('\\n', ' '))\n",
    "        df = df.apply(lambda x: x.replace('\\t', ' '))\n",
    "        df = df.apply(lambda x: x.replace('  ', ' '))\n",
    "        df = df.apply(lambda x: x.lower())\n",
    "        return df\n",
    "\n",
    "    def remove_punctuation(self):\n",
    "        tr = str.maketrans(\"\", \"\", string.punctuation)\n",
    "        # self.data[self.column_name] = self.data[self.column_name].apply(lambda x: \" \".join([item.translate(tr)\n",
    "        #                                                                 for item in x.split()]))\n",
    "        self.data[self.column_name] = self.data[self.column_name].apply(lambda x: x.translate(tr))\n",
    "        return self.data\n",
    "\n",
    "    def stemming(self):\n",
    "        # todo: provide option of selecting stemmer.\n",
    "        snowball_stemmer = SnowballStemmer('english')\n",
    "        # self.data[self.column_name] = self.data[self.column_name].apply(lambda x: \" \".join([snowball_stemmer.stem(item)\n",
    "        #                                                                 for item in x.split()]))\n",
    "        self.data[self.column_name] = self.data[self.column_name].apply(lambda x: \" \".join([self.stemmer.stem(item)\n",
    "                                                                        for item in x.split()]))\n",
    "        return self.data\n",
    "\n",
    "    def lemmatization(self):\n",
    "        self.data[self.column_name] = self.data[self.column_name].apply(lambda x: \" \".join([self.lemmatiser.lemmatize(item)\n",
    "                                                                        for item in x.split()]))\n",
    "        return self.data\n",
    "\n",
    "    def stop_words(self):\n",
    "        stop = stopwords.words('english')\n",
    "        self.data[self.column_name] = self.data[self.column_name].apply(lambda x: \" \".join(set([item for item in x.split() if\n",
    "                                                                                       item not in stop])))\n",
    "        return self.data\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = remove_non_ascii(df)\n",
    "        df = clean_html(df)\n",
    "        return df\n",
    "        \n",
    "    def fit(self, df, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Document'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class PreProcessing(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Custom Pre-Processing estimator for our use-case\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, df):\n",
    "        \"\"\"\n",
    "        Preprocessing steps for text processing\n",
    "        \"\"\"\n",
    "#         columns = df.columns()\n",
    "        df = df.apply(lambda x: x.lower())\n",
    "        df = df.apply(lambda x: \"\".join(i for i in x if ord(i) < 128))\n",
    "        df = df.apply(html.unescape)\n",
    "        return df\n",
    "\n",
    "    def fit(self, df, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('Test1', PreProcess())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx =pipe.fit_transform(df.Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       b\"Pernod takeover talk lifts Domecq\\n\\nShares ...\n",
       "1       b'Qwest may spark MCI bidding war\\n\\nUS phone ...\n",
       "2       b'Dogged Federer claims Dubai crown\\n\\nWorld n...\n",
       "3       b'Oscars race enters final furlong\\n\\nThe race...\n",
       "4       b\"Hearts of Oak 3-2 Cotonsport\\n\\nHearts of Oa...\n",
       "5       b'U2 stars enter rock Hall of Fame\\n\\nSinger B...\n",
       "6       b'News Corp eyes video games market\\n\\nNews Co...\n",
       "7       b'Lewsey puzzle over disallowed try\\n\\nEngland...\n",
       "8       b'Giggs handed Wales leading role\\n\\nRyan Gigg...\n",
       "9       b'India power shares jump on debut\\n\\nShares i...\n",
       "10      b'Ericsson sees earnings improve\\n\\nTelecoms e...\n",
       "11      b'Robinson wants dual code success\\n\\nEngland ...\n",
       "12      b'Fit-again Betsen in France squad\\n\\nFrance h...\n",
       "13      b'Serena ends Sania Mirza\\'s dream\\n\\nSania Mi...\n",
       "14      b'Fockers fuel festive film chart\\n\\nComedy Me...\n",
       "15      b'Pop band Busted to \\'take a break\\'\\n\\nChart...\n",
       "16      b'Hingis to make unexpected return\\n\\nMartina ...\n",
       "17      b'China had role in Yukos split-up\\n\\nChina le...\n",
       "18      b'Zambia confident and cautious\\n\\nZambia\\'s t...\n",
       "19      b\"Reliance unit loses Anil Ambani\\n\\nAnil Amba...\n",
       "20      b'Michael film signals \\'retirement\\'\\n\\nSinge...\n",
       "21      b\"How to make a greener computer\\n\\nThe hi-tec...\n",
       "22      b'Millions to miss out on the net\\n\\nBy 2025, ...\n",
       "23      b'Elton plays Paris charity concert\\n\\nSir Elt...\n",
       "24      b'Former NI minister Scott dies\\n\\nFormer Nort...\n",
       "25      b'Dozens held over ID fraud site\\n\\nTwenty-eig...\n",
       "26      b'Mobiles rack up 20 years of use\\n\\nMobile ph...\n",
       "27      b'Singer Ian Brown \\'in gig arrest\\'\\n\\nFormer...\n",
       "28      b'Disputed Nirvana box set on sale\\n\\nA box se...\n",
       "29      b'How to make a gigapixel picture\\n\\nThe large...\n",
       "                              ...                        \n",
       "2097    b'US cyber security chief resigns\\n\\nThe man m...\n",
       "2098    b'Savvy searchers fail to spot ads\\n\\nInternet...\n",
       "2099    b'Blair\\'s hope for Blunkett return\\n\\nThe eve...\n",
       "2100    b'Ex-PM Lord Callaghan dies aged 92\\n\\nFormer ...\n",
       "2101    b'Jones medals \\'must go if guilty\\'\\n\\nWorld ...\n",
       "2102    b'Blair stresses prosperity goals\\n\\nTony Blai...\n",
       "2103    b'Gronkjaer agrees switch to Madrid\\n\\nJesper ...\n",
       "2104    b'Robinson out of Six Nations\\n\\nEngland capta...\n",
       "2105    b'Games firms \\'face tough future\\'\\n\\nUK vide...\n",
       "2106    b'LSE doubts boost bidders\\' shares\\n\\nShares ...\n",
       "2107    b'Quake\\'s economic costs emerging\\n\\nAsian go...\n",
       "2108    b'Blair joins school sailing trip\\n\\nThe prime...\n",
       "2109    b'Pixies take on Reading and Leeds\\n\\nPixies, ...\n",
       "2110    b'Electrolux to export Europe jobs\\n\\nElectrol...\n",
       "2111    b'Williams stays on despite dispute\\n\\nMatt Wi...\n",
       "2112    b\"Teenager Tait picked for England\\n\\nNewcastl...\n",
       "2113    b'\\'Christmas song formula\\' unveiled\\n\\nA for...\n",
       "2114    b'Connors\\' rallying cry for British tennis\\n\\...\n",
       "2115    b'TV\\'s future down the phone line\\n\\nInternet...\n",
       "2116    b'Grammys honour soul star Charles\\n\\nThe memo...\n",
       "2117    b\"Disney backs Sony DVD technology\\n\\nA next g...\n",
       "2118    b'Labour MP praises Tory campaign\\n\\nThe Conse...\n",
       "2119    b'Cherie accused of attacking Bush\\n\\nCherie B...\n",
       "2120    b'Student \\'fee factor\\' played down\\n\\nA rise...\n",
       "2121    b'Wales critical of clumsy Grewcock\\n\\nWales c...\n",
       "2122    b'Why Cell will get the hard sell\\n\\nThe world...\n",
       "2123    b'Europe blames US over weak dollar\\n\\nEuropea...\n",
       "2124    b'Bekele sets sights on world mark\\n\\nOlympic ...\n",
       "2125    b'Microsoft releases patches\\n\\nMicrosoft has ...\n",
       "2126    b'Share boost for feud-hit Reliance\\n\\nThe boa...\n",
       "Name: Document, Length: 2127, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       b\"Pernod takeover talk lifts Domecq\\n\\nShares ...\n",
       "1       b'Qwest may spark MCI bidding war\\n\\nUS phone ...\n",
       "2       b'Dogged Federer claims Dubai crown\\n\\nWorld n...\n",
       "3       b'Oscars race enters final furlong\\n\\nThe race...\n",
       "4       b\"Hearts of Oak 3-2 Cotonsport\\n\\nHearts of Oa...\n",
       "5       b'U2 stars enter rock Hall of Fame\\n\\nSinger B...\n",
       "6       b'News Corp eyes video games market\\n\\nNews Co...\n",
       "7       b'Lewsey puzzle over disallowed try\\n\\nEngland...\n",
       "8       b'Giggs handed Wales leading role\\n\\nRyan Gigg...\n",
       "9       b'India power shares jump on debut\\n\\nShares i...\n",
       "10      b'Ericsson sees earnings improve\\n\\nTelecoms e...\n",
       "11      b'Robinson wants dual code success\\n\\nEngland ...\n",
       "12      b'Fit-again Betsen in France squad\\n\\nFrance h...\n",
       "13      b'Serena ends Sania Mirza\\'s dream\\n\\nSania Mi...\n",
       "14      b'Fockers fuel festive film chart\\n\\nComedy Me...\n",
       "15      b'Pop band Busted to \\'take a break\\'\\n\\nChart...\n",
       "16      b'Hingis to make unexpected return\\n\\nMartina ...\n",
       "17      b'China had role in Yukos split-up\\n\\nChina le...\n",
       "18      b'Zambia confident and cautious\\n\\nZambia\\'s t...\n",
       "19      b\"Reliance unit loses Anil Ambani\\n\\nAnil Amba...\n",
       "20      b'Michael film signals \\'retirement\\'\\n\\nSinge...\n",
       "21      b\"How to make a greener computer\\n\\nThe hi-tec...\n",
       "22      b'Millions to miss out on the net\\n\\nBy 2025, ...\n",
       "23      b'Elton plays Paris charity concert\\n\\nSir Elt...\n",
       "24      b'Former NI minister Scott dies\\n\\nFormer Nort...\n",
       "25      b'Dozens held over ID fraud site\\n\\nTwenty-eig...\n",
       "26      b'Mobiles rack up 20 years of use\\n\\nMobile ph...\n",
       "27      b'Singer Ian Brown \\'in gig arrest\\'\\n\\nFormer...\n",
       "28      b'Disputed Nirvana box set on sale\\n\\nA box se...\n",
       "29      b'How to make a gigapixel picture\\n\\nThe large...\n",
       "                              ...                        \n",
       "2097    b'US cyber security chief resigns\\n\\nThe man m...\n",
       "2098    b'Savvy searchers fail to spot ads\\n\\nInternet...\n",
       "2099    b'Blair\\'s hope for Blunkett return\\n\\nThe eve...\n",
       "2100    b'Ex-PM Lord Callaghan dies aged 92\\n\\nFormer ...\n",
       "2101    b'Jones medals \\'must go if guilty\\'\\n\\nWorld ...\n",
       "2102    b'Blair stresses prosperity goals\\n\\nTony Blai...\n",
       "2103    b'Gronkjaer agrees switch to Madrid\\n\\nJesper ...\n",
       "2104    b'Robinson out of Six Nations\\n\\nEngland capta...\n",
       "2105    b'Games firms \\'face tough future\\'\\n\\nUK vide...\n",
       "2106    b'LSE doubts boost bidders\\' shares\\n\\nShares ...\n",
       "2107    b'Quake\\'s economic costs emerging\\n\\nAsian go...\n",
       "2108    b'Blair joins school sailing trip\\n\\nThe prime...\n",
       "2109    b'Pixies take on Reading and Leeds\\n\\nPixies, ...\n",
       "2110    b'Electrolux to export Europe jobs\\n\\nElectrol...\n",
       "2111    b'Williams stays on despite dispute\\n\\nMatt Wi...\n",
       "2112    b\"Teenager Tait picked for England\\n\\nNewcastl...\n",
       "2113    b'\\'Christmas song formula\\' unveiled\\n\\nA for...\n",
       "2114    b'Connors\\' rallying cry for British tennis\\n\\...\n",
       "2115    b'TV\\'s future down the phone line\\n\\nInternet...\n",
       "2116    b'Grammys honour soul star Charles\\n\\nThe memo...\n",
       "2117    b\"Disney backs Sony DVD technology\\n\\nA next g...\n",
       "2118    b'Labour MP praises Tory campaign\\n\\nThe Conse...\n",
       "2119    b'Cherie accused of attacking Bush\\n\\nCherie B...\n",
       "2120    b'Student \\'fee factor\\' played down\\n\\nA rise...\n",
       "2121    b'Wales critical of clumsy Grewcock\\n\\nWales c...\n",
       "2122    b'Why Cell will get the hard sell\\n\\nThe world...\n",
       "2123    b'Europe blames US over weak dollar\\n\\nEuropea...\n",
       "2124    b'Bekele sets sights on world mark\\n\\nOlympic ...\n",
       "2125    b'Microsoft releases patches\\n\\nMicrosoft has ...\n",
       "2126    b'Share boost for feud-hit Reliance\\n\\nThe boa...\n",
       "Name: Document, Length: 2127, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
